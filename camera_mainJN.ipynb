{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "595dde68-8486-4ecc-9a97-604dea049292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b9beb5-a4e7-49c0-94aa-cbdb89c95f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gstreamer_pipeline(\n",
    "    capture_width=1280,\n",
    "    capture_height=720,\n",
    "    display_width=1280,\n",
    "    display_height=720,\n",
    "    framerate=60,\n",
    "    flip_method=0,\n",
    "):\n",
    "    return (\n",
    "        \"nvarguscamerasrc ! \"\n",
    "        \"video/x-raw(memory:NVMM), \"\n",
    "        \"width=(int)%d, height=(int)%d, \"\n",
    "        \"format=(string)NV12, framerate=(fraction)%d/1 ! \"\n",
    "        \"nvvidconv flip-method=%d ! \"\n",
    "        \"video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! \"\n",
    "        \"videoconvert ! \"\n",
    "        \"video/x-raw, format=(string)BGR ! appsink\"\n",
    "        % (\n",
    "            capture_width,\n",
    "            capture_height,\n",
    "            framerate,\n",
    "            flip_method,\n",
    "            display_width,\n",
    "            display_height,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f4e5bb1-e846-4c38-8904-d2da30b75899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /home/hong/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ v6.1-272-g8983324 Python-3.6.9 torch-1.10.2 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.0 required by YOLOv5, but Python 3.6.9 is currently installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 213 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='exp16/weights/best.pt', force_reload=True)\n",
    "model.classes = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a475c971-32e1-40c7-adcc-8e63a026e470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvarguscamerasrc ! video/x-raw(memory:NVMM), width=(int)1280, height=(int)720, format=(string)NV12, framerate=(fraction)60/1 ! nvvidconv flip-method=0 ! video/x-raw, width=(int)1280, height=(int)720, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink\n",
      "/home/hong/parking/parkinglot.png written!\n"
     ]
    }
   ],
   "source": [
    "def show_camera():\n",
    "    # To flip the image, modify the flip_method parameter (0 and 2 are the most common)\n",
    "    print(gstreamer_pipeline(flip_method=0))\n",
    "    cap = cv2.VideoCapture(gstreamer_pipeline(flip_method=0), cv2.CAP_GSTREAMER)\n",
    "    if cap.isOpened():\n",
    "        window_handle = cv2.namedWindow(\"CSI Camera\", cv2.WINDOW_AUTOSIZE)\n",
    "        # Window\n",
    "        while cv2.getWindowProperty(\"CSI Camera\", 0) >= 0:\n",
    "            ret_val, img = cap.read()\n",
    "            cv2.imshow(\"CSI Camera\", img)\n",
    "            # This also acts as\n",
    "            keyCode = cv2.waitKey(30) & 0xFF\n",
    "            # Stop the program on the ESC key\n",
    "            if keyCode == 27:\n",
    "                break\n",
    "                \n",
    "            elif keyCode == 32:\n",
    "        # SPACE pressed\n",
    "                img_name = \"/home/hong/parking/parkinglot.png\"\n",
    "                cv2.imshow(img_name, img)\n",
    "                cv2.imwrite(img_name, img)\n",
    "                print(\"{} written!\".format(img_name))\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Unable to open camera\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a13f59e6-47c7-45c6-ad85-d050f9b4d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"/home/hong/parking/parkinglot.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81934105-2af4-447c-8650-788036a57f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1 image to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 (no detections)\n",
      "Speed: 44.2ms pre-process, 734.7ms inference, 138.6ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Images\n",
    "#dir = 'https://github.com/ultralytics/yolov5/raw/master/data/images/'\n",
    "width = 1280\n",
    "height = 720\n",
    "dim = (width, height)\n",
    "img = cv2.imread(img_name, cv2.IMREAD_UNCHANGED)\n",
    "resized = cv2.resize(img, dim)\n",
    "\n",
    "\n",
    "# Inference\n",
    "results = model(resized)\n",
    "\n",
    "# Results\n",
    "results.print()  \n",
    "results.save(labels=False)  # or .show()\n",
    "#results.show()\n",
    "\n",
    "# Data\n",
    "#print(results.xyxy[0])  # print img1 predictions (pixels)\n",
    "#                   x1           y1           x2           y2   confidence        class\n",
    "# tensor([[7.50637e+02, 4.37279e+01, 1.15887e+03, 7.08682e+02, 8.18137e-01, 0.00000e+00],\n",
    "#         [9.33597e+01, 2.07387e+02, 1.04737e+03, 7.10224e+02, 5.78011e-01, 0.00000e+00],\n",
    "#         [4.24503e+02, 4.29092e+02, 5.16300e+02, 7.16425e+02, 5.68713e-01, 2.70000e+01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1909e83-682e-4806-b40a-e805ef913bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=results.pandas().xyxy[0]\n",
    "temp1= pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb7dc9cb-ee15-437e-a82e-469aa7c9a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = temp1.to_numpy()\n",
    "np.savetxt(\"coordinates.txt\", numpy_array, fmt = \"%s\", delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa345432-56a8-4208-87ea-7d3036ed0a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hong/parking/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: genfromtxt: Empty input file: \"coordinates.txt\"\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "filename = 'coordinates.txt'\n",
    "data = np.genfromtxt(filename, delimiter=' ', dtype=None, names=('x1', 'y1', 'x2', 'y2', 'conf', 'class','name'))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf8eb0b9-3403-45fa-8f4b-a023739cfe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.load_model(\"/home/hong/parking/Model/saved_model.h5\")\n",
    "HEIGHT = 49\n",
    "WIDTH = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fefe4bd6-520f-4a04-910a-d245a21cf7dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-41-988023b54aae>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-988023b54aae>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    for line in input_file:\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def show_camera1():\n",
    "    previous = time()\n",
    "    delta = 0\n",
    "    # To flip the image, modify the flip_method parameter (0 and 2 are the most common)\n",
    "    print(gstreamer_pipeline(flip_method=0))\n",
    "    cap1 = cv2.VideoCapture(gstreamer_pipeline(flip_method=0), cv2.CAP_GSTREAMER)\n",
    "    if cap1.isOpened():\n",
    "        window_handle = cv2.namedWindow(\"CSI Camera\", cv2.WINDOW_AUTOSIZE)\n",
    "        # Window\n",
    "        while cv2.getWindowProperty(\"CSI Camera\", 0) >= 0:\n",
    "            ret_val, img = cap1.read()\n",
    "            cv2.imshow(\"CSI Camera\", img)\n",
    "            \n",
    "            current = time()\n",
    "            delta += current - previous\n",
    "            previous = current\n",
    "            \n",
    "            # This also acts as\n",
    "            keyCode = cv2.waitKey(30) & 0xFF\n",
    "            # Stop the program on the ESC key\n",
    "            if keyCode == 27:\n",
    "                break\n",
    "                \n",
    "            elif delta > 30:\n",
    "                img_name = \"/home/hong/parking/test.png\"\n",
    "                cv2.imshow(img_name, img)\n",
    "                cv2.imwrite(img_name, img)\n",
    "                \n",
    "                info1 = []\n",
    "\n",
    "                with open(filename) as input_file:\n",
    "    \n",
    "                    for line in input_file:\n",
    "                        x1, y1, x2, y2, conf, labels, name = (\n",
    "                            item.strip() for item in line.rsplit(' ',6))\n",
    "                        info1.append (dict(zip(('labels', 'conf', 'x1', 'y1', 'x2', 'y2'),\n",
    "                                    (labels, conf, x1, y1, x2, y2))))\n",
    "                \n",
    "                for one_info in info1:\n",
    "                    x1 = int(float(one_info[\"x1\"]))\n",
    "                    y1 = int(float(one_info[\"y1\"]))\n",
    "                    x2 = int(float(one_info[\"x2\"]))\n",
    "                    y2 = int(float(one_info[\"y2\"]))\n",
    "                    cropped_image = img1 [y1:y2, x1:x2]\n",
    "                    image = cv2.resize(cropped_image, (WIDTH, HEIGHT))\n",
    "                    image_x = np.expand_dims(image, axis=0)\n",
    "                    image_x = tf.keras.applications.vgg16.preprocess_input(image_x)\n",
    "                    prediction = model1.predict(image_x)\n",
    "                    prediction = np.squeeze(prediction)\n",
    "\n",
    "                    if prediction> 0.8:\n",
    "                        cv2.rectangle(img1, (x1, y1), (x2, y2),(255, 0, 0), 3)\n",
    "                        occupied = occupied + 1\n",
    "        \n",
    "                    else:\n",
    "                        cv2.rectangle(img1, (x1, y1), (x2, y2),(0, 255, 0), 3)\n",
    "                        empty = empty + 1\n",
    "      \n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(img1, str(occupied),\n",
    "                        (0, 30), font,\n",
    "                        1, (0, 255, 255),\n",
    "                        4, cv2.LINE_AA)\n",
    "                cv2.putText(img1, str(empty),\n",
    "                        (0, 60), font,\n",
    "                        1, (0, 255, 255),\n",
    "                        4, cv2.LINE_AA)\n",
    "                cv2.imshow(\"view\", img1)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "                cv2.waitKey(1)\n",
    "                delta = 0\n",
    "                cap1.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "        else:\n",
    "            print(\"Unable to open camera\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show_camera1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d269e67c-238b-46dc-97d3-aa69d74ceb01",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) /home/nvidia/host/build_opencv/nv_opencv/modules/highgui/src/window.cpp:352: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5fae62ff2879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetWindowProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CSI Camera\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mret_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CSI Camera\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yolov5/utils/general.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(path, im)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# dirs = glob.glob(f\"{path}{sep}*\")  # similar paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m# matches = [re.search(rf\"{path.stem}{sep}(\\d+)\", d) for d in dirs]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0;31m# i = [int(m.groups()[0]) for m in matches if m]  # indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;31m# n = max(i) + 1 if i else 2  # increment number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;31m# path = Path(f\"{path}{sep}{n}{suffix}\")  # increment path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.1) /home/nvidia/host/build_opencv/nv_opencv/modules/highgui/src/window.cpp:352: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "# Initialise variables to store current time difference as well as previous time call value\n",
    "previous = time()\n",
    "delta = 0\n",
    "cap = cv2.VideoCapture(gstreamer_pipeline(flip_method=0), cv2.CAP_GSTREAMER)\n",
    "while True:\n",
    "    # Get the current time, increase delta and update the previous variable\n",
    "    current = time()\n",
    "    delta += current - previous\n",
    "    previous = current\n",
    "    \n",
    "    occupied = int(0)\n",
    "    empty = int(0)\n",
    "    \n",
    "    if cap.isOpened():\n",
    "        window_handle = cv2.namedWindow(\"CSI Camera\", cv2.WINDOW_AUTOSIZE)\n",
    "        # Window\n",
    "        while cv2.getWindowProperty(\"CSI Camera\", 0) >= 0:\n",
    "            ret_val, img = cap.read()\n",
    "            cv2.imshow(\"CSI Camera\", img)\n",
    "            \n",
    "        if delta > 30:\n",
    "            take_pic = cap.read()\n",
    "            cv2.imwrite('/home/hong/parking/test.png', take_pic)\n",
    "            img_name1 = cv2.imread('/home/hong/parking/test.png' , cv2.IMREAD_UNCHANGED)\n",
    "            img1 = cv2.resize(img_name1, dim)\n",
    "        \n",
    "        if keyCode == 27:\n",
    "                break\n",
    "\n",
    "        info1 = []\n",
    "\n",
    "        with open(filename) as input_file:\n",
    "    \n",
    "            for line in input_file:\n",
    "                x1, y1, x2, y2, conf, labels, name = (\n",
    "                    item.strip() for item in line.rsplit(' ',6))\n",
    "                info1.append (dict(zip(('labels', 'conf', 'x1', 'y1', 'x2', 'y2'),\n",
    "                                (labels, conf, x1, y1, x2, y2))))\n",
    "                \n",
    "        for one_info in info1:\n",
    "            x1 = int(float(one_info[\"x1\"]))\n",
    "            y1 = int(float(one_info[\"y1\"]))\n",
    "            x2 = int(float(one_info[\"x2\"]))\n",
    "            y2 = int(float(one_info[\"y2\"]))\n",
    "            cropped_image = img1 [y1:y2, x1:x2]\n",
    "            image = cv2.resize(cropped_image, (WIDTH, HEIGHT))\n",
    "            image_x = np.expand_dims(image, axis=0)\n",
    "            image_x = tf.keras.applications.vgg16.preprocess_input(image_x)\n",
    "            prediction = model1.predict(image_x)\n",
    "            prediction = np.squeeze(prediction)\n",
    "\n",
    "            if prediction> 0.8:\n",
    "                cv2.rectangle(img1, (x1, y1), (x2, y2),(255, 0, 0), 3)\n",
    "                occupied = occupied + 1\n",
    "        \n",
    "            else:\n",
    "                cv2.rectangle(img1, (x1, y1), (x2, y2),(0, 255, 0), 3)\n",
    "                empty = empty + 1\n",
    "      \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img1, str(occupied),\n",
    "                (0, 30), font,\n",
    "                1, (0, 255, 255),\n",
    "                4, cv2.LINE_AA)\n",
    "        cv2.putText(img1, str(empty),\n",
    "                (0, 60), font,\n",
    "                1, (0, 255, 255),\n",
    "                4, cv2.LINE_AA)\n",
    "        cv2.imshow(\"view\", img1)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        delta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f854f-e1b3-48d8-b684-df77c06b45a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
