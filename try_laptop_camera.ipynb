{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d300961-cbf8-4175-967e-3a2bb3b5c06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/parking/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5 ðŸš€ v6.1-111-gb7faeda torch 1.11.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hongjowell/parking/parkinglot.png written!\n",
      "Escape hit, closing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 (no detections)\n",
      "Speed: 9.3ms pre-process, 287.2ms inference, 17.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "Saved 1 image to \u001b[1mruns/detect/exp48\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('/Users/hongjowell/parking2/yolov5', 'custom', path='runs/train/exp16/weights/best.pt', source='local')\n",
    "model.classes = [0]\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"parking lot\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"parking lot\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"/Users/hongjowell/parking/parkinglot.png\"\n",
    "        cv2.imshow(img_name, frame)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Images\n",
    "#dir = 'https://github.com/ultralytics/yolov5/raw/master/data/images/'\n",
    "width = 1280\n",
    "height = 720\n",
    "dim = (width, height)\n",
    "img = cv2.imread(img_name, cv2.IMREAD_UNCHANGED)\n",
    "resized = cv2.resize(img, dim)\n",
    "\n",
    "\n",
    "# Inference\n",
    "results = model(resized)\n",
    "\n",
    "# Results\n",
    "results.print()  \n",
    "results.save(labels=False)  # or .show()\n",
    "#results.show()\n",
    "\n",
    "# Data\n",
    "#print(results.xyxy[0])  # print img1 predictions (pixels)\n",
    "#                   x1           y1           x2           y2   confidence        class\n",
    "# tensor([[7.50637e+02, 4.37279e+01, 1.15887e+03, 7.08682e+02, 8.18137e-01, 0.00000e+00],\n",
    "#         [9.33597e+01, 2.07387e+02, 1.04737e+03, 7.10224e+02, 5.78011e-01, 0.00000e+00],\n",
    "#         [4.24503e+02, 4.29092e+02, 5.16300e+02, 7.16425e+02, 5.68713e-01, 2.70000e+01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a300d-0e5d-4c10-98b9-4318d2bb5663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50195668-1995-4f51-8301-57d7e70a76c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=results.pandas().xyxy[0]\n",
    "temp1= pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724efc3c-318c-4312-b621-b44a9a33059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = temp1.to_numpy()\n",
    "np.savetxt(\"coordinates.txt\", numpy_array, fmt = \"%s\", delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3465d59-c0cb-480c-8f37-b412e6510f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/parking/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: genfromtxt: Empty input file: \"coordinates.txt\"\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "filename = 'coordinates.txt'\n",
    "data = np.genfromtxt(filename, delimiter=' ', dtype=None, names=('x1', 'y1', 'x2', 'y2', 'conf', 'class','name'))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b49a7-e1a9-406f-a476-83b32a15a8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05aefb7e-7647-4340-9e52-19356c9a7cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 11:49:04.377001: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.load_model(\"/Users/hongjowell/parking/Model/saved_model.h5\")\n",
    "HEIGHT = 49\n",
    "WIDTH = 37\n",
    "occupied = int(0)\n",
    "empty = int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b7a1f-44a0-4449-aa08-2ecc0df67ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a2c3c-bc25-40aa-b504-6c03d385d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import cv2\n",
    "\n",
    "# Create a new VideoCapture object\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialise variables to store current time difference as well as previous time call value\n",
    "previous = time()\n",
    "delta = 0\n",
    "while True:\n",
    "    # Get the current time, increase delta and update the previous variable\n",
    "    current = time()\n",
    "    delta += current - previous\n",
    "    previous = current\n",
    "    \n",
    "    if delta > 60:\n",
    "        take_pic = camera.read()\n",
    "        cv2.imwrite('/Users/hongjowell/parking/test.png', take_pic)\n",
    "        img_name1 = cv2.imread('/Users/hongjowell/parking/test.png' , cv2.IMREAD_UNCHANGED)\n",
    "        img1 = cv2.resize(img_name1, dim)\n",
    "\n",
    "        info1 = []\n",
    "\n",
    "        with open(filename) as input_file:\n",
    "    \n",
    "            for line in input_file:\n",
    "                x1, y1, x2, y2, conf, labels, name = (\n",
    "                    item.strip() for item in line.rsplit(' ',6))\n",
    "                info1.append (dict(zip(('labels', 'conf', 'x1', 'y1', 'x2', 'y2'),\n",
    "                                (labels, conf, x1, y1, x2, y2))))\n",
    "                \n",
    "        for one_info in info1:\n",
    "            x1 = int(float(one_info[\"x1\"]))\n",
    "            y1 = int(float(one_info[\"y1\"]))\n",
    "            x2 = int(float(one_info[\"x2\"]))\n",
    "            y2 = int(float(one_info[\"y2\"]))\n",
    "            cropped_image = img1 [y1:y2, x1:x2]\n",
    "            image = cv2.resize(cropped_image, (WIDTH, HEIGHT))\n",
    "            image_x = np.expand_dims(image, axis=0)\n",
    "            image_x = tf.keras.applications.vgg16.preprocess_input(image_x)\n",
    "            prediction = model1.predict(image_x)\n",
    "            prediction = np.squeeze(prediction)\n",
    "\n",
    "            if prediction> 0.8:\n",
    "                cv2.rectangle(img1, (x1, y1), (x2, y2),(255, 0, 0), 3)\n",
    "                occupied = occupied + 1\n",
    "        \n",
    "            else:\n",
    "                cv2.rectangle(img1, (x1, y1), (x2, y2),(0, 255, 0), 3)\n",
    "                empty = empty + 1\n",
    "      \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img1, str(occupied),\n",
    "                (0, 30), font,\n",
    "                1, (0, 255, 255),\n",
    "                4, cv2.LINE_AA)\n",
    "        cv2.putText(img1, str(empty),\n",
    "                (0, 60), font,\n",
    "                1, (0, 255, 255),\n",
    "                4, cv2.LINE_AA)\n",
    "        cv2.imshow(\"view\", img1)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        delta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea70ae8-f51c-41e7-8fd7-a6e422b6aabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc60ff-10a0-4e1d-b172-c2463e15bd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76090794-75b5-4a60-8087-bd905a6e9b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a3e03-1a4d-4536-8643-542bb5b9dc74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0285e2e5-17f3-43ae-8050-9ae503f6a8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df408eb4-88e3-48c8-9f6b-fbe121ad626e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48563de-9b88-4476-a327-23650ad33618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dda5a2-55c3-4041-b5f0-1e8e70262764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959013c7-9e1c-4744-b71a-f75bf2d7e422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a03aa-5c3a-4bff-bd03-18c98c0369ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6098a33-6d06-4804-8949-67d7fb8f848f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95972221-e973-4b5d-ba7b-0f268c8fcaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
